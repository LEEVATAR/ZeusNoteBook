{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99096b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12])\n",
      " list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12])\n",
      " list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])\n",
      " ...\n",
      " list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12])\n",
      " list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12])\n",
      " list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])]\n",
      "(8982,) (2246,)\n",
      "[ 3  4  3 ... 25  3 25]\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]), array([  55,  432,   74, 3159, 1949,   17,   48,   16,  139,  101,  124,\n",
      "        390,   49,  172,   26,   20,  444,   39,   66,  549,  269,  100,\n",
      "         15,   41,   62,   92,   24,   15,   48,   19,   45,   39,   32,\n",
      "         11,   50,   10,   49,   19,   19,   24,   36,   30,   13,   21,\n",
      "         12,   18]))\n",
      "(8982,) (2246,)\n",
      "46\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "87\n",
      "56\n",
      "(8982, 100, 1) (8982,)\n",
      "(2246, 100, 1) (2246,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from sre_parse import Tokenizer\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(   # 로이터 기사 뉴스\n",
    "    num_words=10000, test_split=0.2\n",
    ")\n",
    "\n",
    "print(x_train)\n",
    "print(x_train.shape, x_test.shape)    #(8982,) (2246, ) => 8982개와 2246개의 리스트  => 총 11,228개\n",
    "print(y_train)    \n",
    "print(np.unique(y_train, return_counts=True))    \n",
    "print(y_train.shape, y_test.shape)    #(8982,) (2246, ) => 8982개와 2246개의 리스트  => 총 11,228개\n",
    "print(len(np.unique(y_train)))   # 46개의 label이 있음, 다중분류 \n",
    "\n",
    "print(type(x_train), type(y_train))   # <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
    "print(type(x_train[0]))               # <class 'list'>\n",
    "# print(x_train[0].shape)             # AttributeError: 'list' object has no attribute 'shape'\n",
    "print(len(x_train[0]))                # 87\n",
    "print(len(x_train[1]))                # 56\n",
    "\n",
    "\n",
    "#전처리\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='pre', maxlen=100, truncating='pre')\n",
    "                        #shape=(8982,) => (8982, 100)\n",
    "x_test = pad_sequences(x_test, padding='pre', maxlen=100, truncating='pre')\n",
    "\n",
    "# reshape => LSTM과 Conv1D는 reshape으로 3차원으로 만들어 주어야 함\n",
    "x_train = x_train.reshape(8982, 100, 1)\n",
    "x_test = x_test.reshape(2246, 100, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)     # (8982, 100, 1) (8982, 46)\n",
    "print(x_test.shape, y_test.shape)       # (2246, 100, 1) (2246, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)                        \n",
    "y_test = to_categorical(y_test)                        \n",
    "\n",
    "print(x_train.shape, y_train.shape)     # (8982, 100) (8982, 46)\n",
    "print(x_test.shape, y_test.shape)       # (2246, 100) (2246, 46)\n",
    "\n",
    "# y_train = y_train.reshape(8982, 46, 1)\n",
    "# y_test = y_test.reshape(2246, 46, 1)\n",
    "\n",
    "# print(x_train.shape, y_train.shape)     # (8982, 100) (8982, 46)\n",
    "# print(x_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Embedding(10000, 20, input_length=100))    \n",
    "model.add(LSTM(64, input_shape=(100,1)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "562/562 [==============================] - 79s 141ms/step - loss: 2.2894 - acc: 0.4210\n",
      "Epoch 2/10\n",
      "562/562 [==============================] - 72s 129ms/step - loss: 2.1214 - acc: 0.4667\n",
      "Epoch 3/10\n",
      "562/562 [==============================] - 75s 133ms/step - loss: 2.0841 - acc: 0.4663\n",
      "Epoch 4/10\n",
      "261/562 [============>.................] - ETA: 38s - loss: 2.0461 - acc: 0.4672"
     ]
    }
   ],
   "source": [
    "# 3. 컴파일, 훈련\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "\n",
    "#4. 평가, 예측\n",
    "loss, acc = model.evaluate(x_test, y_test)  # [0]이면 loss, [1]이면 accuracy \n",
    "print('loss : ', loss, 'acc : ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
