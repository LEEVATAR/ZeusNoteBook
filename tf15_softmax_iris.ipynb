{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca54de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47add8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 데이터\n",
    "datasets = load_iris()\n",
    "# print(datasets.DESCR)\n",
    "# print(datasets.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfbdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "x= datasets.data\n",
    "y= datasets.target\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.shape, y.shape)  # (150, 4) (150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081a0c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca92bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, shuffle=True, random_state=72\n",
    ")\n",
    "print(x_train.shape, y_train.shape) # (120, 4) (120, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4710160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델구성\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=4))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e82397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 컴파일, 훈련\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6271c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0943 - accuracy: 0.9688 - val_loss: 0.0620 - val_accuracy: 0.9583\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9792 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9375 - val_loss: 0.1321 - val_accuracy: 0.9583\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1766 - accuracy: 0.9479 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9479 - val_loss: 0.1191 - val_accuracy: 0.9583\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.9271 - val_loss: 0.0521 - val_accuracy: 0.9583\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9583 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1977 - accuracy: 0.9167 - val_loss: 0.1421 - val_accuracy: 0.9583\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1420 - accuracy: 0.9688 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0946 - accuracy: 0.9792 - val_loss: 0.0621 - val_accuracy: 0.9583\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1116 - accuracy: 0.9479 - val_loss: 0.0439 - val_accuracy: 0.9583\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9688 - val_loss: 0.0553 - val_accuracy: 0.9583\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 0.0615 - val_accuracy: 0.9583\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0927 - accuracy: 0.9792 - val_loss: 0.0572 - val_accuracy: 0.9583\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9792 - val_loss: 0.0351 - val_accuracy: 0.9583\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9688 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9479 - val_loss: 0.0804 - val_accuracy: 0.9583\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 0.0648 - val_accuracy: 0.9583\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1020 - accuracy: 0.9792 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9167 - val_loss: 0.0541 - val_accuracy: 0.9583\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.9792 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9583 - val_loss: 0.0645 - val_accuracy: 0.9583\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9792 - val_loss: 0.0411 - val_accuracy: 0.9583\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.9792 - val_loss: 0.0339 - val_accuracy: 0.9583\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9479 - val_loss: 0.0918 - val_accuracy: 0.9583\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1108 - accuracy: 0.9792 - val_loss: 0.0388 - val_accuracy: 0.9583\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.0575 - val_accuracy: 0.9583\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1176 - accuracy: 0.9583 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0922 - accuracy: 0.9688 - val_loss: 0.0504 - val_accuracy: 0.9583\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0862 - accuracy: 0.9792 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1217 - accuracy: 0.9688 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9792 - val_loss: 0.0477 - val_accuracy: 0.9583\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 0.0365 - val_accuracy: 0.9583\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.0415 - val_accuracy: 0.9583\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1378 - accuracy: 0.9375 - val_loss: 0.0962 - val_accuracy: 0.9583\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1449 - accuracy: 0.9583 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1213 - accuracy: 0.9375 - val_loss: 0.0577 - val_accuracy: 0.9583\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0900 - accuracy: 0.9792 - val_loss: 0.0344 - val_accuracy: 0.9583\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0997 - accuracy: 0.9479 - val_loss: 0.0373 - val_accuracy: 0.9583\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1047 - accuracy: 0.9688 - val_loss: 0.0424 - val_accuracy: 0.9583\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1587 - accuracy: 0.9375 - val_loss: 0.1037 - val_accuracy: 0.9583\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1859 - accuracy: 0.9583 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.9479 - val_loss: 0.0859 - val_accuracy: 0.9583\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 0.0343 - val_accuracy: 0.9583\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9688 - val_loss: 0.0581 - val_accuracy: 0.9583\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.9688 - val_loss: 0.0589 - val_accuracy: 0.9583\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.9583 - val_loss: 0.0584 - val_accuracy: 0.9583\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1150 - accuracy: 0.9375 - val_loss: 0.0376 - val_accuracy: 0.9583\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9688 - val_loss: 0.0579 - val_accuracy: 0.9583\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1104 - accuracy: 0.9479 - val_loss: 0.0416 - val_accuracy: 0.9583\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 0.0472 - val_accuracy: 0.9583\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 0.9792 - val_loss: 0.0471 - val_accuracy: 0.9583\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: 0.0464 - val_accuracy: 0.9583\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9792 - val_loss: 0.0352 - val_accuracy: 0.9583\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0799 - accuracy: 0.9792 - val_loss: 0.0463 - val_accuracy: 0.9583\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0829 - accuracy: 0.9792 - val_loss: 0.0500 - val_accuracy: 0.9583\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9792 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0909 - accuracy: 0.9792 - val_loss: 0.0377 - val_accuracy: 0.9583\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1200 - accuracy: 0.9583 - val_loss: 0.0400 - val_accuracy: 0.9583\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0988 - accuracy: 0.9583 - val_loss: 0.0418 - val_accuracy: 0.9583\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0916 - accuracy: 0.9688 - val_loss: 0.0412 - val_accuracy: 0.9583\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1090 - accuracy: 0.9271 - val_loss: 0.0362 - val_accuracy: 0.9583\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1161 - accuracy: 0.9583 - val_loss: 0.0900 - val_accuracy: 0.9583\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9479 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9688 - val_loss: 0.0449 - val_accuracy: 0.9583\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9792 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9583 - val_loss: 0.0920 - val_accuracy: 0.9583\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9688 - val_loss: 0.0348 - val_accuracy: 0.9583\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9375 - val_loss: 0.0375 - val_accuracy: 0.9583\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1291 - accuracy: 0.9583 - val_loss: 0.0469 - val_accuracy: 0.9583\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9375 - val_loss: 0.0492 - val_accuracy: 0.9583\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9583 - val_loss: 0.0385 - val_accuracy: 0.9583\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9167 - val_loss: 0.0824 - val_accuracy: 0.9583\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9375 - val_loss: 0.0336 - val_accuracy: 0.9583\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9375 - val_loss: 0.0355 - val_accuracy: 0.9583\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9688 - val_loss: 0.0558 - val_accuracy: 0.9583\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0880 - accuracy: 0.9688 - val_loss: 0.0379 - val_accuracy: 0.9583\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 0.0680 - val_accuracy: 0.9583\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1177 - accuracy: 0.9583 - val_loss: 0.0368 - val_accuracy: 0.9583\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1184 - accuracy: 0.9375 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9688 - val_loss: 0.0612 - val_accuracy: 0.9583\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 0.9583 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1112 - accuracy: 0.9688 - val_loss: 0.0736 - val_accuracy: 0.9583\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1021 - accuracy: 0.9479 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0755 - accuracy: 0.9792 - val_loss: 0.0914 - val_accuracy: 0.9583\n",
      "Epoch 87/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000Restoring model weights from the end of the best epoch.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1094 - accuracy: 0.9688 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 00087: early stopping\n",
      "걸린 시간 :  8.603594064712524\n"
     ]
    }
   ],
   "source": [
    "#EarlyStopping\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, mode='min',\n",
    "                             verbose=1, restore_best_weights=True)\n",
    "\n",
    "start_time = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=1000, batch_size=10,\n",
    "                validation_split=0.2, \n",
    "                callbacks=[earlyStopping],\n",
    "                verbose=1)\n",
    "end_time = time.time() - start_time\n",
    "print('걸린 시간 : ', end_time) # Epoch 00087: early stopping\n",
    "                                # 걸린 시간 :  8.603594064712524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc419b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "loss :  0.037650417536497116\n",
      "accuracy :  1.0\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "0.037650417536497116\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 평가, 예측\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('loss : ', loss)\n",
    "print('accuracy : ', acc)\n",
    "\n",
    "# result = model.evaluate(x_test, y_test)\n",
    "# print(result[0])\n",
    "# print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bd185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99931216e-01 6.87454231e-05 3.23939211e-20]\n",
      " [5.86912793e-04 9.98944819e-01 4.68270795e-04]\n",
      " [1.58736775e-08 2.09137768e-01 7.90862262e-01]\n",
      " [2.18941292e-08 1.01516180e-01 8.98483813e-01]\n",
      " [9.67379137e-08 3.29509556e-01 6.70490324e-01]\n",
      " [7.69889215e-03 9.92298663e-01 2.43979639e-06]\n",
      " [1.30663524e-04 9.94890332e-01 4.97898413e-03]\n",
      " [1.84573971e-11 1.22652214e-03 9.98773515e-01]\n",
      " [9.99989152e-01 1.08479944e-05 1.45292467e-21]\n",
      " [9.99934435e-01 6.55069744e-05 2.96446875e-19]\n",
      " [9.99879599e-01 1.20411845e-04 7.54287079e-19]\n",
      " [9.99888539e-01 1.11438967e-04 5.61718812e-19]\n",
      " [3.13523960e-05 8.91662538e-01 1.08306035e-01]\n",
      " [9.99999404e-01 5.63053447e-07 3.91431733e-26]\n",
      " [9.99797046e-01 2.02951924e-04 4.38780892e-18]\n",
      " [4.66697893e-05 9.75000143e-01 2.49531511e-02]\n",
      " [8.61526885e-08 9.73739102e-02 9.02625978e-01]\n",
      " [9.99979854e-01 2.01367620e-05 2.81364496e-21]\n",
      " [9.99741614e-01 2.58398562e-04 3.46045901e-18]\n",
      " [9.99999166e-01 8.05417471e-07 3.87709160e-25]\n",
      " [4.97789988e-05 9.99476254e-01 4.73963097e-04]\n",
      " [2.73037593e-10 9.74816177e-03 9.90251899e-01]\n",
      " [9.99743998e-01 2.56023748e-04 1.06239976e-17]\n",
      " [6.10461342e-04 9.99337494e-01 5.20790345e-05]\n",
      " [5.29302924e-04 9.99083519e-01 3.87116364e-04]\n",
      " [3.04019458e-08 1.03463382e-01 8.96536589e-01]\n",
      " [9.99921799e-01 7.82210554e-05 2.19893145e-19]\n",
      " [5.01486613e-12 4.67870064e-04 9.99532104e-01]\n",
      " [1.11063403e-09 7.66569329e-03 9.92334306e-01]\n",
      " [9.99953508e-01 4.65308549e-05 2.91220334e-19]]\n",
      "[0 1 2 2 2 1 1 2 0 0 0 0 1 0 0 1 2 0 0 0 1 2 0 1 1 2 0 2 2 0]\n",
      "[0 1 2 2 2 1 1 2 0 0 0 0 1 0 0 1 2 0 0 0 1 2 0 1 1 2 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)\n",
    "\n",
    "# armax \n",
    "y_predict = y_predict.argmax(axis=1)\n",
    "print(y_predict) \n",
    "# print(y_test)\n",
    "y_test= y_test.argmax(axis=1)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f64d33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(accuracy) :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 정확도 \n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "print('정확도(accuracy) : ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
